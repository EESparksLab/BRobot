NOTES from day 1 of the Winter sprint


We're gonna do everything in Docker

https://robofoundry.medium.com/trying-out-ros2-humble-hawksbill-using-docker-4490bc88c926

https://docs.ros.org/en/humble/Installation.html

https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html

https://roboticseabass.com/2021/04/21/docker-and-ros/

Using PS4 controller with the joy node
https://answers.ros.org/question/362091/ros2-node-for-sony-playstation-4-dual-shock-4-ds4-gamepad/
https://stackoverflow.com/questions/28868393/accessing-bluetooth-dongle-from-inside-docker
Gotten it to work in the ros:humble container (launch using brobot_base shell script). Use Command

ros2 run joy joy_node

this will publish to the /joy topic...
https://github.com/ros-drivers/joystick_drivers/tree/main/joy
http://wiki.ros.org/joy

The next step is to parse the info and pipe it over to the roboclaw I have started to edit joy_driver.py
to do this but

THE CURRENT PROBLEM is that 'import rospy' does not work and installing it through pip is also not working

For communicating to the cameras, we are going to use ssh between the 2 docker containers

https://stackoverflow.com/questions/59035543/how-to-execute-command-from-one-docker-container-to-another
https://stackoverflow.com/questions/3586106/perform-commands-over-ssh-with-python
https://www.cyberciti.biz/faq/noninteractive-shell-script-ssh-password-provider/

NOTES from day 2 of the Winter sprint

Most of today was taken up by Julia (Funeral of a family relative)

Found out that rospy package is actually a ROS 1 thing and has the ROS 2 counterpart called rclpy

Had a discussion about this with chatGPT and here's how that went:

Prompt:
Write an python node for ROS2 that reads from the /joy topic (from the joy node for a generic joystick).
Publish the x and y coordinate of the joystick in a Twist().angular.z and Twist().linear.x to a topic called 'joy_cmd'

Response:
Here is an example of a python ROS2 node that reads from the /joy topic and publishes the x and y coordinates of the joystick to a topic called 'joy_cmd':

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Joy
from geometry_msgs.msg import Twist

class JoystickToTwistNode(Node):
    def __init__(self):
        super().__init__('joystick_to_twist_node')
        self.joy_sub = self.create_subscription(
            Joy, '/joy', self.joy_callback, 10)
        self.cmd_pub = self.create_publisher(Twist, 'joy_cmd', 10)

    def joy_callback(self, joy_msg):
        twist_msg = Twist()
        twist_msg.angular.z = joy_msg.axes[0]
        twist_msg.linear.x = joy_msg.axes[1]
        self.cmd_pub.publish(twist_msg)

def main(args=None):
    rclpy.init(args=args)
    joystick_to_twist_node = JoystickToTwistNode()
    rclpy.spin(joystick_to_twist_node)
    joystick_to_twist_node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()

In this node, we first import the necessary libraries and message types. Then, we define a node called 'joystick_to_twist_node' that subscribes to the '/joy' topic and publishes to the 'joy_cmd' topic.

The node defines a callback function called 'joy_callback' that is called every time a message is received on the '/joy' topic. The callback function reads the x and y coordinates of the joystick from the 'axes' field of the Joy message, and uses them to set the angular.z and linear.x fields of a Twist message. The Twist message is then published to the 'joy_cmd' topic.

Finally, the main function initializes the node, starts the ROS2 event loop, and cleans up when the node is finished.


NOTES from day 3 of the Winter sprint

Holy shit that code actually works!

joy_driver2.py is now operational
    -It reads the right joystick and the left and right face buttons
    -still needs to turn the cameras on and off but we need to build the camera part before we do that
    -Still need to build the ROS2 interface for roboclaw_driver.py

note to self: remember to add the source command to the entrypoint and commit to this docker image

Edited the roboclaw_driver.py to read the ROS2, can't test yet because we need the roboclaw hardware.

Docker image is saved just in case (image name is brobot)

Next is to see if the customizations to the container were even necessary in the first place
    It was not. you can just spin up the osrf/ros:humble-desktop-full and then be on your way!

NOTES from day 4 of the Winter sprint
Correction to that last statement, we need to install the pyserial python module. so theres that

New problem. Roboclaw is working but it cuts out intermittently and then the node crashes.
in order to make it bullet proof we are going to have to make a way to find and reset the device when this happens.



